<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><title>Position Portfolio by Yiwen Zhang</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Position Portfolio for Vibe Coding course - How should we approach creative collaboration with AI?"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><link rel="preload" as="font" type="font/woff2" href="/_astro/inter-latin-wght-normal.Dx4kXJAl.woff2" crossorigin><link rel="stylesheet" href="/_astro/index.CBtif3_f.css">
<link rel="stylesheet" href="/_astro/index.C70zL2-S.css"></head> <body> <!-- Hero Section --> <section class="hero"> <div class="hero-content"> <h1 class="hero-title">Position Portfolio by Yiwen Zhang</h1> <p class="hero-subtitle">How should we approach creative collaboration with AI?</p> </div> <div class="wave-divider"> <svg viewBox="0 0 1440 120" preserveAspectRatio="none"> <path d="M0,40 C320,100 420,20 720,60 C1020,100 1200,20 1440,60 L1440,120 L0,120 Z" fill="#f8f5ff"></path> </svg> </div> </section> <!-- My Position Section --> <section class="section section-light" id="position"> <div class="container"> <h2 class="section-title">My Position</h2> <div class="position-card"> <div class="image-placeholder horizontal"> <span>Image Placeholder</span> </div> <div class="position-content"> <p>I have come to see AI as a valuable creative partner, but only when humans stay responsible for intention, emotion, and meaning-making. Throughout the course, I noticed that AI can broaden what I am able to produce; it helps me generate early drafts quickly, test ideas through rapid prototyping, and explore different design or writing directions that I might not imagine on my own. This acceleration has been transformative for my creative process, allowing me to experiment with multiple approaches simultaneously and iterate at a pace that would be impossible working alone. However, through repeated collaboration, I've discovered that AI does not truly understand context, purpose, or the human experiences that give a project significance. It can mimic patterns and generate plausible content, but it lacks the lived experience, cultural awareness, and emotional intelligence that inform truly meaningful creative work.</p> <p>For this reason, I think of the collaboration as structured but unequalâ€”a partnership where each contributor brings fundamentally different capabilities to the table:</p> <p><strong>AI contributes</strong> speed, variation, pattern recognition, and the ability to iterate endlessly. It can process vast amounts of information, suggest alternatives I hadn't considered, handle repetitive technical tasks, and quickly generate multiple versions of an idea. AI excels at synthesis, combining existing patterns in novel ways, and can serve as an always-available collaborator for brainstorming and exploration. Its tireless capacity for iteration allows me to test hypotheses and refine ideas without the fatigue that typically limits human creative sessions.</p> <p><strong>I contribute</strong> to problem-framing, ethical considerations, personal insight, and the ability to judge what feels appropriate, meaningful, or impactful. I bring the lived experiences, cultural context, and emotional depth that cannot be learned from datasets. I understand my audience not as demographic categories but as real people with complex needs and desires. I can sense when something feels authentic versus derivative, recognize when AI-generated content drifts into clichÃ© or loses cultural specificity, and make nuanced judgments about tone, appropriateness, and impact. Most importantly, I hold the vision for what the work should accomplish and why it matters.</p> <p>Creativity comes when I set clear constraints, communicate my goals with precision, and use AI to push the boundaries of what is possible, while making sure the final direction still reflects my own voice, values, and understanding of the audience or user. I've learned that vague prompts produce vague results, but when I approach AI with specific intentions and well-defined parameters, it becomes a powerful amplifier of my creative capacity. The key is maintaining critical distanceâ€”constantly evaluating AI suggestions rather than accepting them wholesale, and being willing to override or completely discard outputs that don't align with my vision.</p> <p class="highlight-text">In short: AI can enhance and stretch my creative capacity, but humans must remain the authors who hold the vision and make the final decisions.</p> </div> </div> </div> <div class="angled-divider"> <svg viewBox="0 0 1440 80" preserveAspectRatio="none"> <polygon points="0,0 1440,80 0,80" fill="#fff5f0"></polygon> </svg> </div> </section> <!-- Evidence From My Making Section --> <section class="section section-warm" id="evidence-making"> <div class="container"> <h2 class="section-title">Evidence From My Making</h2> <div class="cards-grid"> <!-- Card 1 --> <div class="evidence-card card-peach"> <div class="image-placeholder card-image"> <span>Image Placeholder</span> </div> <div class="card-content"> <h3 class="card-title"> <span class="card-icon">ðŸ“–</span>
Interactive Story: Li Wei's Day in a Rural School
</h3> <p>In creating this interactive narrative about educational inequality in rural China, AI proved invaluable for technical scaffoldingâ€”helping me brainstorm branching paths, structure the decision tree, and organize the narrative flow. The system could quickly generate multiple story branches and suggest logical consequences for different choices, dramatically speeding up the structural development process. However, a critical limitation emerged when I attempted to let AI propose emotional or cultural details: it consistently drifted into stereotypes and clichÃ©s that felt superficial and inauthentic. AI-generated descriptions of the rural setting leaned on generic imagery of poverty without capturing the specific dignity, resilience, and complexity of rural Chinese communities. The emotional beats it suggested felt manufactured rather than genuine, lacking the nuance that comes from understanding how real people navigate difficult circumstances with agency and hope.</p> <p class="key-insight"><strong>Key insight:</strong> AI is excellent at structural scaffolding and mechanical complexity, but authentic emotion, cultural specificity, and truthful representation must come from humans who understand context and lived experience. The system can build the skeleton, but humans must provide the heart.</p> </div> </div> <!-- Card 2 --> <div class="evidence-card card-teal"> <div class="image-placeholder card-image"> <span>Image Placeholder</span> </div> <div class="card-content"> <h3 class="card-title"> <span class="card-icon">ðŸ“Š</span>
Outfit Recommender & Data Visualization Map
</h3> <p>This project revealed AI's dual nature most clearly: technically powerful yet entirely dependent on how clearly I framed the task. When I provided precise specifications for data processing, visualization parameters, and user interface requirements, AI excelled at implementationâ€”generating clean code, suggesting optimization strategies, and helping me troubleshoot errors efficiently. However, when my instructions were ambiguous or when I asked AI to make design decisions without clear criteria, the collaboration faltered. Vague prompts like "make the visualization more engaging" produced suggestions that ranged from irrelevant to counterproductive, while specific requests like "use a color gradient from warm to cool tones to represent temperature variation, with labels positioned at 45-degree angles" yielded exactly what I needed. The experience taught me that AI functions as a mirror of my own clarity: garbage in, garbage out, but precision in, power out.</p> <p class="key-insight"><strong>Key insight:</strong> AI does not reduce complexity or solve poorly defined problemsâ€”it reflects and amplifies whatever clarity or confusion the human brings to the collaboration. Clear goals, specific constraints, and well-defined success criteria enable productive partnership; vague prompts and ambiguous objectives cause drift and wasted effort. The burden of problem definition remains firmly on human shoulders.</p> </div> </div> <!-- Card 3 --> <div class="evidence-card card-lavender"> <div class="image-placeholder card-image"> <span>Image Placeholder</span> </div> <div class="card-content"> <h3 class="card-title"> <span class="card-icon">ðŸŒ¸</span>
WonderGarden Game
</h3> <p>This was my most joyful and successful collaboration with AI, and the one that most clearly illuminated the ideal division of labor between human and machine. AI served as an excellent technical partner, helping me debug complex interaction systems, optimize performance issues, and rapidly iterate on game mechanics. When I encountered problems with collision detection or animation timing, AI could quickly suggest solutions and help me test multiple approaches. The development cycle accelerated dramatically because I could offload technical troubleshooting while maintaining focus on the creative vision. However, the emotional core of the gameâ€”the calmness, the softness, the sense of gentle wonder and meditative explorationâ€”came completely from me. These qualities emerged from my own need for peaceful, non-competitive digital experiences, from my aesthetic preferences shaped by years of observing nature and art, and from my understanding of what creates emotional safety and openness in interactive experiences. AI could implement the mechanics I described, but it couldn't originate the vision of a garden as a space for contemplation rather than conquest.</p> <p class="key-insight"><strong>Key insight:</strong> AI can efficiently build mechanics, solve technical problems, and accelerate implementation, but humans create meaning, emotional resonance, and intentional experience design. The most successful collaborations occur when AI handles technical execution while humans maintain ownership of vision, purpose, and emotional truth. Joy in creative work comes from this clarity of roles.</p> </div> </div> </div> </div> <div class="wave-divider wave-down"> <svg viewBox="0 0 1440 120" preserveAspectRatio="none"> <path d="M0,60 C240,20 480,100 720,60 C960,20 1200,100 1440,60 L1440,120 L0,120 Z" fill="#f0f7ff"></path> </svg> </div> </section> <!-- Evidence From Readings Section --> <section class="section section-blue" id="evidence-readings"> <div class="container"> <h2 class="section-title">Evidence From Readings</h2> <div class="readings-timeline"> <div class="reading-item"> <div class="reading-icon"> <span>ðŸ“š</span> </div> <div class="reading-content"> <h3>Crawford â€” Atlas of AI</h3> <p>Crawford's critical examination of AI systems helped me understand the fundamental reason why AI feels strong in pattern generation but weak in emotional grounding and cultural authenticity: it is trained on data extracted from human activity, not on lived experience itself. AI learns statistical correlations in text, images, and other media, but it has no embodied understanding of what these patterns mean in the messy reality of human life. When I struggled with AI producing cultural stereotypes in my interactive story, Crawford's framework helped me recognize this wasn't a bug to be fixed with better promptsâ€”it was a fundamental limitation arising from how AI systems abstract human experience into training data. AI can recognize and reproduce patterns associated with "rural poverty" or "educational inequality" in its training corpus, but it cannot understand these phenomena as lived realities experienced by real people with agency, dignity, and complex inner lives. This reading reframed my expectations: I stopped trying to get AI to produce culturally authentic content and instead focused on using it for structural tasks while contributing the human truth myself.</p> </div> </div> <div class="reading-item"> <div class="reading-icon"> <span>ðŸ§ </span> </div> <div class="reading-content"> <h3>Weizenbaum â€” On Machine "Understanding"</h3> <p>Weizenbaum's classic critique of artificial intelligence clarified why AI fundamentally struggles with intention, meaning, and true understanding, even when its outputs appear sophisticated and contextually appropriate. His central argumentâ€”that there is a profound difference between simulating intelligent behavior and actually understandingâ€”directly addressed challenges I encountered across all my projects. When AI helped me with the outfit recommender and data visualization, it could predict what code structures would be stylistically consistent with my existing codebase and what visualization approaches might be conventionally "engaging," but it had no understanding of why I was creating these tools, who would use them, or what problems they were meant to solve. AI operates through pattern prediction and statistical correlation; humans operate through intentionality and purposeful meaning-making. This distinction helped me reframe my prompting strategy: instead of expecting AI to understand my goals and make aligned decisions, I learned to provide explicit decision criteria and treat AI outputs as raw materials requiring human judgment and interpretation. Weizenbaum reminded me that fluent, plausible text is not the same as understanding, and technical capability is not the same as wisdom.</p> </div> </div> <div class="reading-item"> <div class="reading-icon"> <span>ðŸ¤–</span> </div> <div class="reading-content"> <h3>Epstein et al. â€” Anthropomorphizing AI</h3> <p>This research on anthropomorphization illuminated a critical trap I needed to avoid: mistaking AI's linguistic fluency and conversational style for actual agency, understanding, or collaborative intention. The paper demonstrated how easily humans project human-like qualities onto AI systems, especially when those systems use first-person language and conversational patterns that feel natural and responsive. This tendency became particularly relevant during my WonderGarden development, where AI's helpful responses and apparent "understanding" of my creative vision could easily lead me to treat it as a creative partner with its own ideas and intentions rather than as a sophisticated pattern-matching tool. Epstein's work reminded me to maintain critical awareness of this distinction: AI can be a collaborator in practiceâ€”a useful tool that extends my capabilities and helps me think through problemsâ€”but not a collaborator in agency. The system has fluency without consciousness, responsiveness without understanding, and consistency without values. Recognizing this helped me avoid the pitfall of deferring creative decisions to AI or assuming its suggestions carried any inherent validity beyond statistical patterns in its training data. I learned to appreciate AI's utility while remaining the sole source of intentionality and judgment in our collaboration.</p> </div> </div> </div> </div> <div class="angled-divider angled-reverse"> <svg viewBox="0 0 1440 80" preserveAspectRatio="none"> <polygon points="0,80 1440,0 1440,80" fill="#4a5568"></polygon> </svg> </div> </section> <!-- Synthesis Section --> <section class="section section-dark" id="synthesis"> <div class="container"> <h2 class="section-title section-title-light">Synthesis</h2> <div class="synthesis-content"> <p>My position emerged from the dynamic interplay between hands-on making and theoretical reading, each informing and deepening my understanding of the other. The practical challenges I encountered in my projects became comprehensible through theoretical frameworks, while abstract concepts from readings became concrete and actionable when applied to real creative work.</p> <ul class="synthesis-list"> <li><strong>The story project revealed AI's cultural limits and tendency toward stereotypes</strong> â†’ Crawford's "Atlas of AI" explained why this occurs: AI learns from data patterns divorced from lived experience, embodied understanding, and cultural context. My frustration with AI-generated clichÃ©s wasn't a prompting failureâ€”it reflected the fundamental gap between pattern recognition and genuine cultural competence.</li> <li><strong>The data project showed AI's absolute dependence on clear human direction</strong> â†’ Weizenbaum clarified the limits of machine "understanding" and why vague prompts produce vague results. AI doesn't truly understand project goals or user needs; it predicts stylistically appropriate responses based on training patterns. My responsibility as the human collaborator is to provide the understanding and intention that AI lacks.</li> <li><strong>The WonderGarden game felt like genuine creative collaboration</strong> â†’ Epstein's research on anthropomorphization reminded me not to mistake AI's fluency and responsiveness for actual agency or creative partnership. The satisfying collaboration I experienced came from AI effectively executing my clearly communicated vision, not from AI contributing its own creative intentions. Recognizing this distinction preserves human authorship while acknowledging AI's utility.</li> </ul> <p class="synthesis-conclusion">Together, these insightsâ€”both practical and theoreticalâ€”shaped my stance: AI powerfully expands creative capacity and enables new forms of exploration, but only when humans maintain responsibility for setting intention, providing context, making ethical judgments, and authoring meaning. The collaboration works when roles are clear and humans remain the decision-makers.</p> </div> </div> <div class="wave-divider"> <svg viewBox="0 0 1440 120" preserveAspectRatio="none"> <path d="M0,40 C360,100 540,20 900,60 C1260,100 1380,40 1440,60 L1440,120 L0,120 Z" fill="#ffffff"></path> </svg> </div> </section> <!-- Final Position Section --> <section class="section section-white" id="final-position"> <div class="container"> <div class="final-card"> <h2 class="final-title">Final Position</h2> <p class="final-text">AI expands what I can imagine and build, dramatically accelerating my creative process and enabling exploration at scales previously impossible. However, this expansion only creates genuine value when I direct the vision with clarity, define the ethical boundaries with care, and interpret the meaning with human wisdom and cultural understanding. Creative collaboration with AI works best when I leverage the system's strengthsâ€”tireless iteration, pattern synthesis, technical execution, and rapid prototypingâ€”while maintaining human ownership of the elements that AI cannot provide: intentionality, emotional truth, cultural authenticity, ethical judgment, and purposeful meaning-making. Through my experience making interactive narratives, data visualizations, and games, supported by critical readings on AI's fundamental limitations, I've learned that successful human-AI collaboration requires both appreciation for AI's capabilities and clear-eyed recognition of its limitations. AI is neither a threat to human creativity nor a replacement for human judgmentâ€”it is a powerful tool that amplifies human capacity when used with intention, criticality, and maintained authorship. The future of creative work lies not in ceding control to AI, but in thoughtfully choreographing the division of labor between human insight and machine capability, always ensuring that humans remain the authors of meaning, purpose, and vision.</p> </div> </div> </section> <!-- Footer --> <footer class="footer"> <p>Position Portfolio by Yiwen Zhang â€¢ Vibe Coding Course</p> </footer> </body></html>